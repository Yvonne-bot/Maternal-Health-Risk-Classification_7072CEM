{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b087b0f9-ad62-41f8-8435-9770e9ce75c4",
   "metadata": {},
   "source": [
    "# MATERNAL HEALTH RISK LEVEL CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803286ee",
   "metadata": {},
   "source": [
    "*****************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a379fa9",
   "metadata": {},
   "source": [
    "# Name : Yvonne Musinguzi \n",
    "# Student No: 15094816"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3f155b",
   "metadata": {},
   "source": [
    "*********************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f977285",
   "metadata": {},
   "source": [
    "# Link to dataset \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8e3f56-9fe8-43db-8ef4-988df523880b",
   "metadata": {},
   "source": [
    "https://archive.ics.uci.edu/dataset/863/maternal+health+risk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3f7e73",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c512d-a94f-4b60-98d5-35ee95058bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import StackingClassifier, BaggingClassifier, VotingClassifier \n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841ec170",
   "metadata": {},
   "source": [
    "*****************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fe7449-7506-4534-9a8d-a727cd753922",
   "metadata": {},
   "source": [
    "# Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c378af32-3118-4e3b-843d-56a5afc69580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix Seeds for Reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Load Data\n",
    "df = pd.read_csv(\"C:/Users/user/OneDrive - Coventry University/Desktop/Maternal Health Risk Data Set.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213116e0",
   "metadata": {},
   "source": [
    "*********"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4acafc8-eb17-498a-97c2-79b60012b78b",
   "metadata": {},
   "source": [
    "# Identifying Dataset Structure and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0966a057-767d-4d91-a884-5f295797a06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Schema & Investigate for missing values \n",
    "print(df.info())\n",
    "print(\"\\nMissing Values:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747a5066-70b1-4f72-ba4d-b64815805b42",
   "metadata": {},
   "source": [
    "\n",
    "# Comments:\n",
    "1. The dataset has 1014 instances and luckily there are no missing values.\n",
    "\n",
    "2. The target feature is RiskLevel (categorical) so there will be nedd for encoding.\n",
    "\n",
    "3. The predictor features are Age, SystolicBP,DiastolicBP,BS,BodyTemp, HeartRate which are all numerical values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1841c07",
   "metadata": {},
   "source": [
    "*****************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1c79c4-4aca-4f8e-9b92-5d50789ba007",
   "metadata": {},
   "source": [
    "# Understanding the count and distribution of our target classes (RiskLevel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7607d8-20c1-4713-bef1-f034f9902267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class count and Distribution \n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = sns.countplot(data=df, x='RiskLevel', palette='Set2')\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x() + p.get_width() / 2., height + 1,f'{int(height)}', ha=\"center\", fontsize=10, color=\"black\" )\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc8656c-3477-44e7-a522-fc2c42cd90d9",
   "metadata": {},
   "source": [
    "# Comments\n",
    "1. low risk has the highest count, followed by mid risk and high risk has a lowest count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201d9cf2",
   "metadata": {},
   "source": [
    "********"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a4c46d-f9e2-4075-9f78-05a542cfcc85",
   "metadata": {},
   "source": [
    "# Checking for Duplicated Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d3961b-b85e-47f5-aef0-460ea7245af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Duplicates\n",
    "dups = df[df.duplicated()]\n",
    "print(f\"\\nNumber of duplicated rows: {len(dups)}\")\n",
    "if not dups.empty:\n",
    "    print(\"Sample duplicated rows:\")\n",
    "    print(dups.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb2c169-c8d7-455d-bdc9-0dc975ab8efa",
   "metadata": {},
   "source": [
    "# Comments\n",
    "1. Duplication in a dataset can cause bias and subsequently cause overfitting\n",
    "2. In this case 562 duplicates is alot compared to the total number of rows(1014)\n",
    "3. It might be better to drop the duplicates and leave only the first one using (df = df.drop_duplicates())\n",
    "4. However, in this case i will leave the duplicated values and first explore the dataset because the dataset is already limited."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ba087b",
   "metadata": {},
   "source": [
    "*********"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2220dfa1-11f4-4deb-80bc-7e1d3b2430a8",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4023ae-0a6d-4a8f-a1ec-f614bf0023a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Target Variable before correlation matrix\n",
    "labelEncoder = LabelEncoder()\n",
    "df['RiskLevel'] = labelEncoder.fit_transform(df['RiskLevel'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d3e90d-f8b5-4379-ade3-890655caf6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict={\"high risk\":0,\"low risk\":1,\"mid risk\":2}\n",
    "labels_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18657b8-0462-4a54-8d51-11de62a3bd6e",
   "metadata": {},
   "source": [
    "# comments \n",
    "1. The target variable (RiskLevel) is categorical and should be encoded for easy processing\n",
    "2. I have stored the labels in a dictionary so that i can easily locate them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2da7a7",
   "metadata": {},
   "source": [
    "***********"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def4aacd",
   "metadata": {},
   "source": [
    "# Correlation HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24385ddc-4529-4973-bd05-2e9eff9d7f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap\n",
    "feature_cols = [\"Age\", \"SystolicBP\", \"DiastolicBP\", \"BS\", \"BodyTemp\",\"HeartRate\"] \n",
    "plt.figure(figsize=(10, 6))\n",
    "corr = df[feature_cols + ['RiskLevel']].corr()\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d421ae-1b34-49db-87dd-040347c69ec3",
   "metadata": {},
   "source": [
    "# Comments\n",
    "1. SystolicBP and  DiastolicBP have a high strong correlation with correlation coeffiecient of 0.79. It means that as one increases, the other also increases hence the assumption that SystolicBP and  DiastolicBP are providing simIlar information trends.(Multicolinearity)\n",
    "2. Multicolinearity makes it hard to estimate the effect of the individual variable on the target.\n",
    "3. because they provide the same information, it might be better to drop one.\n",
    "4. However, just like mentioned before the dataset is quite limited and carrying out further analysis before dropping any of them is important.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3529d35",
   "metadata": {},
   "source": [
    "**************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b42ae14-0fac-4dee-84c2-6e580f92a7f2",
   "metadata": {},
   "source": [
    "# Multivariate Analysis:Correlation Between Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c293c4a4-9e13-4e81-9d63-0bb9465bfc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot to Explore Variable Relationships\n",
    "df_viz = df.copy()\n",
    "df_viz['RiskLevel'] = labelEncoder.inverse_transform(df['RiskLevel'])\n",
    "sns.pairplot(df_viz, hue=\"RiskLevel\", diag_kind=\"kde\", palette=\"Set1\")\n",
    "plt.suptitle(\"Pairplot of Features by Risk Level\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0034f450-d6c5-4346-810e-ac33bc4eb6ad",
   "metadata": {},
   "source": [
    "# Observations\n",
    "1. HeartRate seems to have little or no influence on the distribution of the target classes regardardless of the varaiables.\n",
    "2. Dropping HeartRate completely might be considered since it doesn't contribute significantly to the class distribution.However, further exploration      will be done to come to an informed decision. \n",
    "3. There is a clear outlier indicated for the HeartRate varaiable and that should be looked at.\n",
    "4. There is a clear oulier indicated for the the SystolicBP variable and that should also be looked at.\n",
    "\n",
    "# Multivariate analysis with Age\n",
    "1. Younger women with Lower BodyTemp generally have lower risk and Young women with high BodyTemp generally have higher risk.However,older women with      high BodyTemp have low risk while old women with low BodyTemp have high risk\n",
    "2. Old women with low BS have low risk but generally, both young and old women have high risk as the BS increases\n",
    "3. Both young and old women have high risk as the DiastolicBP increases.\n",
    "4. Both young and old women have high risk as the SystolicBP increases.\n",
    "\n",
    "# Multivariate analysis with SystolicBP\n",
    "1. Women with lower BodyTemp and lower SystolicBP have lower risk however,women with high SystolicBP are generally at high risk regardless of their BodyTemp.\n",
    "2. Women with lower BS and low SystolicBP have lower risks however as the SystolicBP increases and the BS increases, the RiskLevel also increaes.\n",
    "3. It is still evident that the correlation between SystolicBP and DiastolicBP is high and the RiskLevel increases as both increase.  \n",
    "\n",
    "# Multivariate analysis with DiastolicBP\n",
    "1. There is a clear outlier for the low risk class and should be considered to be removed if it doesnt carry so much information.\n",
    "2. Women with low DiastolicBP and low BodyTemp, BS, SystolicBP and Age are generally at lower risk. However from 60 mmHg upwards, the RiskLevel increases as the DiastolicBP increseases regardless of the other variable.\n",
    "\n",
    "# Multivariate analysis with BS\n",
    "1. Women with a low BodyTemp have high risk regardless of their BS Levels.\n",
    "2. Generally, women with high BS Levels have a high risk.\n",
    "3. Also women with low BS but older age have lower risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19169dd2",
   "metadata": {},
   "source": [
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e436da07-69c6-4b77-ba7a-478b497a2431",
   "metadata": {},
   "source": [
    "# Multivariate Analysis:Average Feature Values per Risk Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd388c90-62f4-420d-ae12-e110e426191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Feature Values per Risk Level\n",
    "grouped = df_viz.groupby('RiskLevel')[feature_cols].mean().T\n",
    "grouped.plot(kind='bar', figsize=(8, 4), colormap='Set1')\n",
    "plt.title(\"Average Feature Values per Risk Level\")\n",
    "plt.ylabel(\"Mean Value\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1101fd00",
   "metadata": {},
   "source": [
    "**************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc85c2bc-1c5f-4921-a52a-442b05d69b74",
   "metadata": {},
   "source": [
    "# Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb88c41b-905f-4516-9727-8d771b220e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Distribution by Risk Level\n",
    "for col in feature_cols:\n",
    "    plt.figure(figsize=(4, 2))\n",
    "    sns.histplot(data=df_viz, x=col, hue=\"RiskLevel\", kde=True, palette=\"Set1\", element=\"step\", stat=\"density\")\n",
    "    plt.title(f\"Risk Level by {col}  \")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1849657e",
   "metadata": {},
   "source": [
    "**********************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d90d0de-51b7-4bfb-9b7e-cfe97900f3b9",
   "metadata": {},
   "source": [
    "# Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd7cd0a-7452-4dea-9873-7a409c6ea1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Outliers with Boxplots\n",
    "feature_cols = [\"Age\", \"SystolicBP\", \"DiastolicBP\", \"BS\", \"BodyTemp\",\"HeartRate\"] \n",
    "plt.figure(figsize=(8, 5))\n",
    "for i, col in enumerate(feature_cols):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    sns.boxplot(data=df, y=col, palette=\"viridis\")\n",
    "    plt.title(f\"Boxplot - {col}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c59505-f9a4-49e5-9a2e-960c8fbac213",
   "metadata": {},
   "source": [
    "# Comments\n",
    "1. As earlier discovered in the pairsplot, there is a clear outlier that is way out range for the HeartRate varaible and SystolicBP variable. \n",
    "2. I will be dropping the outliers from HeartRate and SystolicBP.\n",
    "3. The other variables also have outliers but they dont seem to be way over the range of values. I will leave them for now since the dataset is quite limited. But it is worth noting that outliers may skew distributions,cause overfitting and generally mislead results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cee221b",
   "metadata": {},
   "source": [
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0701fd12",
   "metadata": {},
   "source": [
    "# Removing the prominent outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f53345f-9582-45a0-af10-db9602357afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to remove outliers from\n",
    "columns_to_clean = ['HeartRate', 'SystolicBP']\n",
    "\n",
    "# Loop through each column and apply the IQR method\n",
    "for col in columns_to_clean:\n",
    "    Q1 = df[col].quantile(0.25)  # 25th percentile\n",
    "    Q3 = df[col].quantile(0.75)  # 75th percentile\n",
    "    IQR = Q3 - Q1                # Interquartile range\n",
    "\n",
    "    # Define bounds\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Keep only rows within the bounds\n",
    "    df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9790e07a-7bde-45c7-996e-82b00b0046ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f775417-61f8-4095-b4b8-5d59ff2a4b51",
   "metadata": {},
   "source": [
    "# Comments\n",
    "1. we now have 1002 rows after dropping the outliers from HeartRate and SystolicBP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d56821d",
   "metadata": {},
   "source": [
    "********************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cef5321-ea77-4269-8dfa-c6630976f6e6",
   "metadata": {},
   "source": [
    "# Pre Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524471eb-9ebf-449b-9c94-9b5e6bd71b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Features & Target\n",
    "X = df[feature_cols]\n",
    "y = df['RiskLevel']\n",
    "\n",
    "# Normalize Features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply SMOTE to Balance Classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Show Class Distribution After SMOTE with Total Counts\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.countplot(x=y_train_smote,palette='Set2')\n",
    "plt.title(\"Class Distribution (After SMOTE)\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height())}', \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', fontsize=12, color='black', xytext=(0, 5), \n",
    "                textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af54bfbb-24d6-4787-a600-7ffe0b07a014",
   "metadata": {},
   "source": [
    "# Comments \n",
    "1. Encoding:The target variable has been encoded to convert categorical values into numerical format, making it suitable for machine learning algorithms.\n",
    "\n",
    "2. Scaling:\n",
    "The predictor variables have been scaled to ensure that all features contribute equally to the learning process. This prevents variables with larger magnitudes from disproportionately influencing the model.\n",
    "\n",
    "3. Splitting:\n",
    "The dataset is split into training and testing sets using an 80/20 ratio. This allows the model to learn from one portion of the data and be evaluated on unseen data to assess its performance.\n",
    "\n",
    "4. SMOTE (Synthetic Minority Over-sampling Technique):\n",
    "SMOTE is applied to the training data to address class imbalance, which was identified earlier. This technique generates synthetic examples for the minority class, improving the model's ability to learn from imbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957ccefe",
   "metadata": {},
   "source": [
    "**************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c1e382-79b6-4231-8e90-b9edcf2e9476",
   "metadata": {},
   "source": [
    "# Training the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4318979-2b1c-464c-98ba-05f555cd2e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"SVM\": SVC(probability=True, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=1),\n",
    "    \"XGBoost\": xgb.XGBClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Train & Evaluate Models\n",
    "accuracy_results = []\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "    y_train_pred = model.predict(X_train_smote)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_acc = accuracy_score(y_train_smote, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_test_prob = model.predict_proba(X_test)\n",
    "        auc_score = roc_auc_score(y_test, y_test_prob, multi_class='ovr')\n",
    "        print(f\"{model_name}: AUC Score = {auc_score:.4f}\")\n",
    "    else:\n",
    "        auc_score = None\n",
    "        print(f\"{model_name}: AUC Score not available\")\n",
    "\n",
    "    accuracy_results.append((model_name, train_acc, test_acc, auc_score))\n",
    "    print(f\"{model_name}: Training Accuracy = {train_acc:.4f}, Test Accuracy = {test_acc:.4f}\")\n",
    "    print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42465f53",
   "metadata": {},
   "source": [
    "**********************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ca4ea1-f615-4ebc-a78c-71458fcb2561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Comparison Table\n",
    "df_results = pd.DataFrame(accuracy_results, columns=[\"Model\", \"Training Accuracy\", \"Test Accuracy\", \"AUC Score\"])\n",
    "df_results_sorted = df_results.sort_values(by=\"Test Accuracy\", ascending=False)\n",
    "print(\"\\nModel Comparison Table:\")\n",
    "df_results_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bdec88-0e53-4ac0-a516-33db91042092",
   "metadata": {},
   "source": [
    "# Comments:\n",
    "1. The highest training accuracy was observed across all three models — Random Forest, XGBoost, and Decision Tree — at 94.7%,indicating that the models fit the training data very well.\n",
    "\n",
    "2. The highest AUC score was achieved by XGBoost (0.9461), suggesting it is the most effective at distinguishing between classes.\n",
    "\n",
    "3. In terms of test accuracy, Random Forest performed best with 80.1%, followed closely by XGBoost. \n",
    "   However, the consistent 94.7% training accuracy across models, coupled with a drop in test accuracy (especially for Decision Tree), \n",
    "   may indicate overfitting — where the models perform exceptionally well on training data but not as well on unseen data.\n",
    "\n",
    "4. To address this,cross-validation (Stratified 5-Fold Cross-Validation) will be applied to  to assess model generalizability and ensure that the performance is stable across different subsets of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1315e6f0",
   "metadata": {},
   "source": [
    "*******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7e9ec4",
   "metadata": {},
   "source": [
    " # Stratified 5-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee4cfd5-16e8-4caf-a46b-517ffa5e82cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Stratified 5-Fold Cross-Validation\n",
    "kf_5 = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_results_5 = []\n",
    "for model_name, model in models.items():\n",
    "    scores = cross_val_score(model, X_scaled, y, cv=kf_5, scoring=\"accuracy\")\n",
    "    mean_acc = scores.mean()\n",
    "    cv_results_5.append((model_name, mean_acc))\n",
    "    print(f\"{model_name}: Mean Accuracy (5-Fold CV) = {mean_acc:.4f}\")\n",
    "\n",
    "df_results_cv_5 = pd.DataFrame(cv_results_5, columns=[\"Model\", \"Mean Accuracy\"])\n",
    "df_results_cv_sorted_5 = df_results_cv_5.sort_values(by=\"Mean Accuracy\", ascending=False)\n",
    "print(\"\\n Model Comparison Table (5-Fold CV):\")\n",
    "df_results_cv_sorted_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c019e615-fed6-4e06-96d8-9ea5b37849f4",
   "metadata": {},
   "source": [
    "# Comments:\n",
    "1. Applying Stratified 5-Fold Cross-Validation, the test accuracy increases from 80.10% (single split for Random Forest) to 85.73% \n",
    "   (mean cross-validation accuracy for Random Forest).\n",
    "\n",
    "2. XGBoost also benefits, with test accuracy improving from 79.60% (single split) to 85.03% (cross-validation mean).\n",
    "\n",
    "3. For KNN, the test accuracy improves from 76.12% (single split) to 85.03% (cross-validation mean), and similarly, \n",
    "   Decision Tree sees an increase from 77.11% to 83.93%.\n",
    "\n",
    "4. The significant increase in test accuracy after cross-validation indicates that the models generalize better and the risk of overfitting is reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1989ca",
   "metadata": {},
   "source": [
    "****************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaee78a1",
   "metadata": {},
   "source": [
    "# Stratified 10-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9df8801-ea3f-46c0-aa76-1bce190b4bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Stratified 10-Fold Cross-Validation\n",
    "kf_10= StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_results_10 = []\n",
    "for model_name, model in models.items():\n",
    "    scores = cross_val_score(model, X_scaled, y, cv=kf_10, scoring=\"accuracy\")\n",
    "    mean_acc = scores.mean()\n",
    "    cv_results_10.append((model_name, mean_acc))\n",
    "    print(f\"{model_name}: Mean Accuracy (10-Fold CV) = {mean_acc:.4f}\")\n",
    "\n",
    "df_results_cv_10 = pd.DataFrame(cv_results_10, columns=[\"Model\", \"Mean Accuracy\"])\n",
    "df_results_cv_10_sorted = df_results_cv_10.sort_values(by=\"Mean Accuracy\", ascending=False)\n",
    "print(\"\\n Model Comparison Table (10-Fold CV):\")\n",
    "df_results_cv_10_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b738d26a-7e60-4158-b530-c5b818a0719b",
   "metadata": {},
   "source": [
    "# Comment:\n",
    "1. Applying Stratified 10-Fold Cross-Validation show minimal change from the 5-fold, suggesting that increasing the number of folds from 5 to 10 does not significantly impact the models accuracy but just cause a small change.\n",
    "   \n",
    "3. XGBoost has now the highest accuracy at 85.73%, while Random Forest follows closely at 85.54%.\n",
    "   \n",
    "5. So far, these are our highest performing models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7ab20f",
   "metadata": {},
   "source": [
    "***************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4ae69e-8089-4a34-98ac-cbb6a9bf9dac",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56adc106-65d2-4ef1-834f-e25583419f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Random Forest\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "random_forest.fit(X_train_smote, y_train_smote)\n",
    "importances = random_forest.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_cols, 'Importance': importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=feature_importance_df[\"Importance\"], y=feature_importance_df[\"Feature\"], palette=\"viridis\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Feature Importance (Random Forest)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650e3869-f3f5-4f8e-afb8-65a76dde0e8e",
   "metadata": {},
   "source": [
    "# Comments:\n",
    "1. With feature importance, we are trying to understand if some features are as significant to the model or if they should be dropped. \n",
    "2. So far, i think i will keep all the features and explore hyperparameter tuning to further improve the perfomance of the model. \n",
    "3. It should be noted that since this is sensitive topic and could mean life or death, it is important that the accuracy and robustness \n",
    "   of the model is very good.(Above 90%)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53919ee2",
   "metadata": {},
   "source": [
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b080ff9-3c97-4185-bcaf-8fc72632427a",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e05e823-4a02-44a9-8c08-099f201f5837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameter grids for each model\n",
    "param_grids = {\n",
    "    \"Logistic Regression\": {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'solver': ['liblinear', 'lbfgs'],\n",
    "        'max_iter': [100, 200, 300]\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [50,100, 200, 300],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    \"Naive Bayes\": {\n",
    "        'var_smoothing': [1e-9, 1e-8, 1e-7]\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        'n_neighbors': [1, 5, 10, 15],\n",
    "        'metric': ['euclidean', 'manhattan'],\n",
    "        'weights': ['uniform', 'distance']\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        'learning_rate': [0.01, 0.1, 0.3],\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.8, 0.9, 1.0]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c35d53-dfec-44ce-a074-546f9d0b62d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initialize a dictionary to store the best models, AUC scores, and cross-validation results\n",
    "best_models = {}\n",
    "\n",
    "# Perform GridSearchCV for each model\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Hyperparameter tuning for {model_name}...\")\n",
    "    \n",
    "    # Perform GridSearchCV\n",
    "    grid_search = GridSearchCV(model, param_grids[model_name], cv=10, n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "    grid_search.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "    # Get the best model and parameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    \n",
    "    # Perform 5-fold cross-validation for accuracy\n",
    "    cv_accuracy = cross_val_score(best_model, X_train_smote, y_train_smote, cv=10, scoring='accuracy')\n",
    "    mean_accuracy = cv_accuracy.mean()\n",
    "\n",
    "    # Perform AUC score calculation (for classification models)\n",
    "    best_model.fit(X_train_smote, y_train_smote)\n",
    "    y_pred_prob = best_model.predict_proba(X_test)  \n",
    "    auc_score = roc_auc_score(y_test, y_pred_prob, multi_class='ovr')  \n",
    "    \n",
    "    # Store the results\n",
    "    best_models[model_name] = {\n",
    "        \"Best Model\": best_model,\n",
    "        \"Best Params\": best_params,\n",
    "        \"Mean Accuracy (10-Fold CV)\": mean_accuracy,\n",
    "        \"AUC Score\": auc_score\n",
    "    }\n",
    "    \n",
    "    print(f\"Best parameters for {model_name}: {best_params}\")\n",
    "    print(f\"Mean Accuracy (10-Fold CV) for {model_name}: {mean_accuracy}\")\n",
    "    print(f\"AUC Score for {model_name}: {auc_score}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "for model_name, result in best_models.items():\n",
    "    print(f\"{model_name} - Best AUC Score: {result['AUC Score']}, Mean Accuracy: {result['Mean Accuracy (10-Fold CV)']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2430acd4",
   "metadata": {},
   "source": [
    "*****************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d35a2f1-263d-4318-9044-0ba4c0db0a26",
   "metadata": {},
   "source": [
    "# Application of the hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ef98d3-0e1e-49bf-b8ae-1fff3f398f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of models with tuned hyperparameters\n",
    "models_2 = {\n",
    "    \"Logistic Regression\": LogisticRegression(C=0.1, max_iter=100, solver='liblinear'),\n",
    "    \"Random Forest\": RandomForestClassifier(max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50, random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB(var_smoothing=1e-09),\n",
    "    \"SVM\": SVC(C=10, gamma='auto', kernel='rbf', probability=True),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=None, min_samples_leaf=1, min_samples_split=2, random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(metric='euclidean', n_neighbors=15, weights='uniform'),\n",
    "    \"XGBoost\": xgb.XGBClassifier(learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8, use_label_encoder=False, \n",
    "                                 eval_metric='mlogloss', random_state=42)\n",
    "}\n",
    "\n",
    "# Initialize result lists\n",
    "results = []\n",
    "\n",
    "# Loop through models and evaluate\n",
    "for name, model in models_2.items():\n",
    "    # Fit model on training data\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    # Predict on training and test data\n",
    "    y_train_pred = model.predict(X_train_smote)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Accuracy\n",
    "    train_acc = accuracy_score(y_train_smote, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # AUC score (handle models without predict_proba)\n",
    "    try:\n",
    "        y_test_proba = model.predict_proba(X_test)\n",
    "        auc = roc_auc_score(y_test, y_test_proba, multi_class='ovr', average='macro')\n",
    "    except:\n",
    "        auc = np.nan  # Not available for this model\n",
    "    \n",
    "    # 10-Fold Cross Validation on training data\n",
    "    cv_acc = cross_val_score(model, X_train_smote, y_train_smote, cv=10, scoring='accuracy').mean()\n",
    "    \n",
    "    # Append results\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Training Accuracy': round(train_acc, 4),\n",
    "        'Test Accuracy': round(test_acc, 4),\n",
    "        'AUC Score': round(auc, 4) if not np.isnan(auc) else 'N/A',\n",
    "        'CV Accuracy (10-Fold)': round(cv_acc, 4)\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_final_results = pd.DataFrame(results)\n",
    "df_final_results.sort_values(by='CV Accuracy (10-Fold)', ascending=False, inplace=True)\n",
    "\n",
    "# Display result table\n",
    "print(\"\\n Model Comparison Table with hyperparameter tuning and 10-Fold CV:\")\n",
    "df_final_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c97ef3-36ac-4c08-8c45-f45c8fea5606",
   "metadata": {},
   "source": [
    "# Comments:\n",
    "1. With the application of the hyperparameter tuning and Stratified 10-Fold Cross-Validation, Random Forest achieved the highest\n",
    "   10-Fold CV accuracy at 86.68%, followed closely by XGBoost at 86.17%.\n",
    "2. The 10-Fold Cross-Validation accuracy represents the average testing accuracy across 10 different validation sets. It provides a more robust and reliable estimate of the model's performance on unseen data, compared to accuracy from a single train-test split.\n",
    "3. AUC scores remained high for both models — 0.9337 for Random Forest and 0.9448 for XGBoost — confirming strong class separation ability and consistent predictive power.\n",
    "3. What if we wanted to have even a better model with better perfomance? We could consider applying ensembling techniques by combining the best performing models and leveraging their strengths and maximize the predictive power, resulting in a more robust and accurate final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33414f3a",
   "metadata": {},
   "source": [
    "************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d36d949-8fed-4918-9516-abc6ba468cd8",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c86619b-279d-4ac1-81b5-8825f2d7f56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Voting Classifier with top-performing models (using 'soft' voting for classification)\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rf', RandomForestClassifier(max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50, random_state=42)),\n",
    "    ('xgb', xgb.XGBClassifier(learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8, use_label_encoder=False, \n",
    "                                 eval_metric='mlogloss', random_state=42)),\n",
    "    ('knn', KNeighborsClassifier(metric='euclidean', n_neighbors=15, weights='uniform')),\n",
    "    ('dt', DecisionTreeClassifier(max_depth=None, min_samples_leaf=1, min_samples_split=2, random_state=42))   \n",
    "], voting='soft')  \n",
    "\n",
    "# Train the Voting Classifier (soft voting)\n",
    "voting_clf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Evaluate the Voting Classifier (soft voting for classification)\n",
    "voting_train_pred = voting_clf.predict(X_train_smote)\n",
    "voting_test_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# Calculate Accuracies for the entire Voting Classifier\n",
    "voting_train_acc = accuracy_score(y_train_smote, voting_train_pred)\n",
    "voting_test_acc = accuracy_score(y_test, voting_test_pred)\n",
    "\n",
    "# Now calculate AUC for the entire Voting Classifier (using 'predict_proba' for soft voting)\n",
    "voting_train_auc = roc_auc_score(y_train_smote, voting_clf.predict_proba(X_train_smote), multi_class='ovr')\n",
    "voting_test_auc = roc_auc_score(y_test, voting_clf.predict_proba(X_test), multi_class='ovr')\n",
    "\n",
    "# Print the AUC and Accuracy for the Voting Classifier as a whole\n",
    "print(f\"Voting Classifier AUC (Training): {voting_train_auc:.4f}\")\n",
    "print(f\"Voting Classifier AUC (Test): {voting_test_auc:.4f}\")\n",
    "print(f\"Voting Classifier Accuracy (Training): {voting_train_acc:.4f}\")\n",
    "print(f\"Voting Classifier Accuracy (Test): {voting_test_acc:.4f}\")\n",
    "\n",
    "# 10-Fold Cross Validation for AUC and Accuracy (using the whole Voting Classifier)\n",
    "CV = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "CV_train_auc = cross_val_score(voting_clf, X_train_smote, y_train_smote, cv=CV, scoring='roc_auc_ovr', n_jobs=-1)\n",
    "CV_train_acc = cross_val_score(voting_clf, X_train_smote, y_train_smote, cv=CV, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Print the results for 10-fold CV for the entire Voting Classifier\n",
    "print(f\"Average AUC score (10-fold CV): {np.mean(CV_train_auc):.4f}\")\n",
    "print(f\"Average Training Accuracy (10-fold CV): {np.mean(CV_train_acc):.4f}\")\n",
    "\n",
    "# Print classification report for the Voting Classifier\n",
    "print(classification_report(y_test, voting_test_pred))\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, voting_test_pred)\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=voting_clf.classes_)\n",
    "cmd.plot(cmap='Blues', values_format='d')\n",
    "\n",
    "# For multi-class classification, we'll binarize the labels and calculate the AUC per class\n",
    "y_train_bin = label_binarize(y_train_smote, classes=[0, 1, 2])  # Adjust classes as needed\n",
    "y_test_bin = label_binarize(y_test, classes=[0, 1, 2])  # Adjust classes as needed\n",
    "\n",
    "# Calculate ROC curve and AUC for each class in the training set\n",
    "fpr_train, tpr_train, roc_auc_train = {}, {}, {}\n",
    "for i in range(y_train_bin.shape[1]):\n",
    "    fpr_train[i], tpr_train[i], _ = roc_curve(y_train_bin[:, i], voting_clf.predict_proba(X_train_smote)[:, i])\n",
    "    roc_auc_train[i] = auc(fpr_train[i], tpr_train[i])  # Changed 'auc' to 'roc_auc_train[i]'\n",
    "\n",
    "# Calculate ROC curve and AUC for each class in the test set\n",
    "fpr_test, tpr_test, roc_auc_test = {}, {}, {}\n",
    "for i in range(y_test_bin.shape[1]):\n",
    "    fpr_test[i], tpr_test[i], _ = roc_curve(y_test_bin[:, i], voting_clf.predict_proba(X_test)[:, i])\n",
    "    roc_auc_test[i] = auc(fpr_test[i], tpr_test[i])  # Changed 'auc' to 'roc_auc_test[i]'\n",
    "\n",
    "# Plotting the ROC curve for each class\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['blue', 'red', 'green']  # Adjust color as needed\n",
    "for i in range(y_train_bin.shape[1]):\n",
    "    plt.plot(fpr_train[i], tpr_train[i], color=colors[i], label=f'Training AUC Class {i} = {roc_auc_train[i]:.4f}')\n",
    "    plt.plot(fpr_test[i], tpr_test[i], color=colors[i], linestyle='--', label=f'Test AUC Class {i} = {roc_auc_test[i]:.4f}')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Random classifier line\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Voting Classifier')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdf040d-ed47-4b9c-a25f-2eec043e2231",
   "metadata": {},
   "source": [
    "# Comments:\n",
    "1. This voting classifier utilises an ensemble approach, combining the best performing classifiers to enhance performance:Random Forest Classifier (rf)\n",
    "   XGBoost Classifier (xgb),K-Nearest Neighbors Classifier (knn) and Decision Tree Classifier (dt)\n",
    "2. Training AUC (0.9925): The model performs excellently in distinguishing between classes on the training data, with a very high Area Under the Curve (AUC) score, indicating a strong ability to separate the classes.\n",
    "3. Test AUC (0.9420): The model retains its strong classification ability on unseen data, showing good generalization to new data points.\n",
    "4. Training Accuracy (0.9474): The model fits the training data very well, with a high accuracy score. However, this may also indicate overfitting if not balanced with test data performance.\n",
    "5. Test Accuracy (0.8010): The model's performance drops on test data, suggesting overfitting, where the model performs well on training data but struggles to generalize on unseen examples.\n",
    "6. 10-Fold Cross-Validation:Average AUC (0.9512): Cross-validation confirms the model's ability to generalize well across different subsets of data, with a solid AUC score.Average Training Accuracy (0.8545): The model shows strong accuracy across multiple folds, indicating robustness and consistency in performance.\n",
    "7. Class 0 (Precision 0.91, Recall 0.81, F1-score 0.86): The model is highly precise in identifying Class 0, though it could improve recall (identifying all instances of Class 0).\n",
    "8. Class 1 (Precision 0.84, Recall 0.75, F1-score 0.79): The model performs well for Class 1, balancing both precision and recall, though there is some room for improvement in precision.\n",
    "9. Class 2 (Precision 0.70, Recall 0.85, F1-score 0.77): The model struggles with precision for Class 2, suggesting that while it identifies most instances, it sometimes misclassifies instances as Class 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3971457f",
   "metadata": {},
   "source": [
    "*********"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392aa2c1-f3bf-42c8-9e47-ffb8739367c4",
   "metadata": {},
   "source": [
    "# Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becb6094-929a-4217-a0d0-893b7fdb337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Base models with tuned hyperparameters\n",
    "base_estimators = [\n",
    "    ('rf', RandomForestClassifier(max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50, random_state=42)),\n",
    "    ('xgb', xgb.XGBClassifier(learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.8, use_label_encoder=False, \n",
    "                                 eval_metric='mlogloss', random_state=42)),\n",
    "    ('knn', KNeighborsClassifier(metric='euclidean', n_neighbors=15, weights='uniform')),\n",
    "    ('dt', DecisionTreeClassifier(max_depth=None, min_samples_leaf=1, min_samples_split=2, random_state=42))  \n",
    "]\n",
    "\n",
    "# Initialize the Stacking Classifier\n",
    "stacking_clf = StackingClassifier(estimators=base_estimators, final_estimator=RandomForestClassifier(n_estimators=50, random_state=42))\n",
    "\n",
    "# Create a Stratified K-Fold cross-validation object (10 folds)\n",
    "kf_stacking = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Store AUC scores for each fold\n",
    "auc_scores = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# k-Fold Cross Validation\n",
    "for train_index, val_index in kf_stacking.split(X_train_smote, y_train_smote):\n",
    "    # Split the data into training and validation sets\n",
    "    X_train_fold, X_val_fold = X_train_smote[train_index], X_train_smote[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_smote[train_index], y_train_smote[val_index]\n",
    "    \n",
    "    # Fit the model on the current fold\n",
    "    stacking_clf.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Make predictions\n",
    "    train_pred = stacking_clf.predict(X_train_fold)\n",
    "    val_pred = stacking_clf.predict(X_val_fold)\n",
    "    \n",
    "    # Calculate training and validation accuracy for this fold\n",
    "    train_acc = accuracy_score(y_train_fold, train_pred)\n",
    "    val_acc = accuracy_score(y_val_fold, val_pred)\n",
    "    \n",
    "    # Calculate predicted probabilities for AUC\n",
    "    val_prob = stacking_clf.predict_proba(X_val_fold)\n",
    "    \n",
    "    # If binary classification, use probabilities for the positive class (column 1)\n",
    "    if len(set(y_val_fold)) == 2:\n",
    "        auc_score = roc_auc_score(y_val_fold, val_prob[:, 1])\n",
    "    else:\n",
    "        # For multiclass, use one-vs-rest AUC\n",
    "        y_val_bin = label_binarize(y_val_fold, classes=[0, 1, 2])  # Adjust classes as needed\n",
    "        auc_score = roc_auc_score(y_val_bin, val_prob, average='macro', multi_class='ovr')\n",
    "    \n",
    "    # Store the AUC and accuracy for each fold\n",
    "    auc_scores.append(auc_score)\n",
    "    train_accuracies.append(train_acc)\n",
    "    test_accuracies.append(val_acc)\n",
    "\n",
    "# Calculate the average AUC score, training accuracy, and validation accuracy across all folds\n",
    "average_auc = np.mean(auc_scores)\n",
    "average_train_acc = np.mean(train_accuracies)\n",
    "average_val_acc = np.mean(test_accuracies)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Average AUC score (10-fold CV): {average_auc:.4f}\")\n",
    "print(f\"Average Training Accuracy: {average_train_acc:.4f}\")\n",
    "print(f\"Average 10-Fold Validation Accuracy: {average_val_acc:.4f}\")\n",
    "\n",
    "# Finally, train the model on the full training set and evaluate on the test set\n",
    "stacking_clf.fit(X_train_smote, y_train_smote)\n",
    "stacking_test_pred = stacking_clf.predict(X_test)\n",
    "stacking_train_pred = stacking_clf.predict(X_train_smote)\n",
    "\n",
    "stacking_test_acc = accuracy_score(y_test, stacking_test_pred)\n",
    "stacking_train_acc = accuracy_score(y_train_smote, stacking_train_pred)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, stacking_test_pred)\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=stacking_clf.classes_)\n",
    "cmd.plot(cmap='Blues', values_format='d')\n",
    "\n",
    "# Print Test Accuracy and Classification Report\n",
    "print(f\"Stacking Classifier Test Accuracy: {stacking_test_acc:.4f}\")\n",
    "print(f\"Stacking Classifier Train Accuracy: {stacking_train_acc:.4f}\")\n",
    "print(classification_report(y_test, stacking_test_pred))\n",
    "\n",
    "# ROC Curve and AUC Calculation\n",
    "# Binarize labels for multiclass classification\n",
    "y_test_bin = label_binarize(y_test, classes=[0, 1, 2])  # Adjust classes as needed\n",
    "y_train_bin = label_binarize(y_train_smote, classes=[0, 1, 2])  # Adjust classes as needed\n",
    "\n",
    "# Calculate ROC curve and AUC for each class in the test set\n",
    "fpr_test, tpr_test, roc_auc_test = {}, {}, {}\n",
    "fpr_train, tpr_train, roc_auc_train = {}, {}, {}\n",
    "\n",
    "for i in range(y_test_bin.shape[1]):\n",
    "    # Test ROC\n",
    "    fpr_test[i], tpr_test[i], _ = roc_curve(y_test_bin[:, i], stacking_clf.predict_proba(X_test)[:, i])\n",
    "    roc_auc_test[i] = auc(fpr_test[i], tpr_test[i])\n",
    "    \n",
    "    # Train ROC\n",
    "    fpr_train[i], tpr_train[i], _ = roc_curve(y_train_bin[:, i], stacking_clf.predict_proba(X_train_smote)[:, i])\n",
    "    roc_auc_train[i] = auc(fpr_train[i], tpr_train[i])\n",
    "\n",
    "# Plotting the ROC curve for both train and test\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot ROC curve for each class in the test set\n",
    "colors = ['blue', 'red', 'green']  # Adjust colors for different classes as needed\n",
    "for i in range(y_test_bin.shape[1]):\n",
    "    plt.plot(fpr_test[i], tpr_test[i], color=colors[i], label=f'Test Class {i} AUC = {roc_auc_test[i]:.4f}')\n",
    "    plt.plot(fpr_train[i], tpr_train[i], color=colors[i], linestyle='--', label=f'Train Class {i} AUC = {roc_auc_train[i]:.4f}')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Random classifier line\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Stacking Classifier (Train & Test)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a5300d-ae17-4eb6-aca6-65821ebf14a9",
   "metadata": {},
   "source": [
    "# Comments:\n",
    "1. Ensemble Composition:The model combines Random Forest (rf), XGBoost (xgb), K-Nearest Neighbors (knn), and Decision Tree (dt) classifiers, with a Random Forest meta-model making the final predictions. This ensemble approach leverages the strengths of multiple models to improve performance.\n",
    "2. AUC Scores:Training AUC (0.9925): The model performs excellently on the training data, showing strong class separation with a very high AUC score. This indicates that the model can effectively distinguish between different classes in the training set.\n",
    "3. Test AUC (0.9420): The model retains good generalization to unseen data, maintaining a high AUC score. This shows it is able to classify unseen data with reasonable accuracy.\n",
    "4. Accuracy:Training Accuracy (0.9395): The model fits the training data well, achieving high accuracy. However, this might indicate potential overfitting, as the training accuracy is higher than test accuracy.Test Accuracy (0.8159): The model's performance drops on the test data, which is common when there is overfitting. The drop from the training accuracy suggests that the model struggles to generalize to new, unseen examples.\n",
    "5. Cross-Validation:Average AUC (0.9456): The model performs consistently well across multiple cross-validation folds, confirming its ability to generalize effectively across various subsets of the data.Average Training Accuracy (0.9395): The model shows robust performance on training data, with stable results across the different cross-validation folds.\n",
    "6. Average 10-Fold Validation Accuracy (0.8494): While still strong, this slightly lower accuracy compared to training accuracy suggests that the model is not perfectly generalized but still performs well across different subsets.\n",
    "7. Class-wise Performance:Class 0 (Precision: 0.91, Recall: 0.77, F1-score: 0.84): The model performs very well in precision, meaning it accurately identifies most of the instances of Class 0. However, recall is slightly lower, meaning some Class 0 instances are not being captured.\n",
    "Class 1 (Precision: 0.86, Recall: 0.81, F1-score: 0.84): The model shows a balanced performance for Class 1, with good precision and recall. However, a slight improvement in precision could reduce misclassifications of other classes as Class 1.\n",
    "Class 2 (Precision: 0.72, Recall: 0.85, F1-score: 0.78): The model performs well in recall, identifying a high proportion of Class 2 instances. However, the lower precision suggests that many instances are being misclassified as Class 2, which needs to be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d3b3d7",
   "metadata": {},
   "source": [
    "*************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b7221f-1642-4a7e-9875-47c745df98bd",
   "metadata": {},
   "source": [
    "# Random Forest Classifier with hyperparameter tuning and \n",
    "# Stratified 10-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d992adb1-8acb-46a2-b348-95bdb10391bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Predict on test data for Random Forest\n",
    "rf_pred = models_2['Random Forest'].predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "rf_train_acc = accuracy_score(y_train_smote, models_2['Random Forest'].predict(X_train_smote))\n",
    "rf_test_acc = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "# AUC Score (only for models with predict_proba)\n",
    "try:\n",
    "    rf_proba = models_2['Random Forest'].predict_proba(X_test)\n",
    "    rf_auc = roc_auc_score(y_test, rf_proba, multi_class='ovr', average='macro')\n",
    "except:\n",
    "    rf_auc = 'N/A'\n",
    "\n",
    "# 10-Fold Cross Validation on training data\n",
    "rf_cv_acc = cross_val_score(models_2['Random Forest'], X_train_smote, y_train_smote, cv=10, scoring='accuracy').mean()\n",
    "\n",
    "# Classification Report\n",
    "rf_class_report = classification_report(y_test, rf_pred)\n",
    "\n",
    "# Performance Report\n",
    "print(\"Random Forest - Performance Report\")\n",
    "\n",
    "print(\"RF-Training Accuracy:\", round(rf_train_acc, 4))\n",
    "print(\"RF-Test Accuracy:\", round(rf_test_acc, 4))\n",
    "print(\"RF-AUC Score:\", rf_auc)\n",
    "print(\"RF-10-Fold Cross Validation Accuracy:\", round(rf_cv_acc, 4))\n",
    "\n",
    "# Display classification report\n",
    "print(\"\\nClassification Report:\\n\", rf_class_report)\n",
    "\n",
    "# Plot Confusion Matrix for Random Forest\n",
    "def plot_confusion_matrix(model, X_test, y_test, model_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "    disp.plot(cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.show()\n",
    "\n",
    "# Confusion Matrix for Random Forest\n",
    "plot_confusion_matrix(models_2['Random Forest'], X_test, y_test, 'Random Forest')\n",
    "\n",
    "# ROC Curve and AUC Calculation\n",
    "# Binarize labels for multiclass classification\n",
    "y_test_bin = label_binarize(y_test, classes=[0, 1, 2])  # Adjust classes as needed\n",
    "y_train_bin = label_binarize(y_train_smote, classes=[0, 1, 2])  # Binarize training labels\n",
    "\n",
    "# Predict probabilities for both train and test datasets\n",
    "rf_proba_train = models_2['Random Forest'].predict_proba(X_train_smote)\n",
    "\n",
    "# Calculate ROC curve and AUC for each class in the test set\n",
    "fpr_test, tpr_test, roc_auc_test = {}, {}, {}\n",
    "for i in range(y_test_bin.shape[1]):\n",
    "    fpr_test[i], tpr_test[i], _ = roc_curve(y_test_bin[:, i], rf_proba[:, i])\n",
    "    roc_auc_test[i] = auc(fpr_test[i], tpr_test[i])\n",
    "\n",
    "# Calculate ROC curve and AUC for each class in the train set\n",
    "fpr_train, tpr_train, roc_auc_train = {}, {}, {}\n",
    "for i in range(y_train_bin.shape[1]):\n",
    "    fpr_train[i], tpr_train[i], _ = roc_curve(y_train_bin[:, i], rf_proba_train[:, i])\n",
    "    roc_auc_train[i] = auc(fpr_train[i], tpr_train[i])\n",
    "\n",
    "# Plotting the ROC curve for both train and test data\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['blue', 'red', 'green']  # Adjust colors for different classes as needed\n",
    "\n",
    "# Plot ROC curve for each class - Test data\n",
    "for i in range(y_test_bin.shape[1]):\n",
    "    plt.plot(fpr_test[i], tpr_test[i], color=colors[i], label=f'Test Class {i} AUC = {roc_auc_test[i]:.4f}')\n",
    "\n",
    "# Plot ROC curve for each class - Train data\n",
    "for i in range(y_train_bin.shape[1]):\n",
    "    plt.plot(fpr_train[i], tpr_train[i], color=colors[i], linestyle='--', label=f'Train Class {i} AUC = {roc_auc_train[i]:.4f}')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Random classifier line\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Random Forest - Train vs Test')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bf12c4",
   "metadata": {},
   "source": [
    "***********************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f78919-f72c-4151-ad29-fb74a41dec27",
   "metadata": {},
   "source": [
    "# XGBoost Classifier with hyperparameter tuning and \n",
    "# Stratified 10-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac318c-7caf-4886-9896-e95fd958bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Predicting on test data for XGBoost\n",
    "y_test_pred_xgb = models_2['XGBoost'].predict(X_test)\n",
    "\n",
    "# Generate classification report\n",
    "xgb_classification_report = classification_report(y_test, y_test_pred_xgb)\n",
    "print(\"XGBoost - Classification Report:\\n\")\n",
    "print(xgb_classification_report)\n",
    "\n",
    "# Predicting probabilities for AUC\n",
    "y_test_proba_xgb = models_2['XGBoost'].predict_proba(X_test)\n",
    "y_train_proba_xgb = models_2['XGBoost'].predict_proba(X_train_smote)\n",
    "\n",
    "# AUC Score (multi-class)\n",
    "auc_xgb = roc_auc_score(y_test, y_test_proba_xgb, multi_class='ovr', average='macro')\n",
    "\n",
    "# Training accuracy\n",
    "train_acc_xgb = accuracy_score(y_train_smote, models_2['XGBoost'].predict(X_train_smote))\n",
    "\n",
    "# Testing accuracy\n",
    "test_acc_xgb = accuracy_score(y_test, y_test_pred_xgb)\n",
    "\n",
    "# 10-Fold Cross Validation\n",
    "cv_acc_xgb = cross_val_score(models_2['XGBoost'], X_train_smote, y_train_smote, cv=10, scoring='accuracy').mean()\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"\\nXGBoost - AUC Score:\", round(auc_xgb, 4))\n",
    "print(\"XGBoost - Training Accuracy:\", round(train_acc_xgb, 4))\n",
    "print(\"XGBoost - Testing Accuracy:\", round(test_acc_xgb, 4))\n",
    "print(\"XGBoost - CV Accuracy (10-Fold):\", round(cv_acc_xgb, 4))\n",
    "\n",
    "# Confusion Matrix for XGBoost\n",
    "plot_confusion_matrix(models_2['XGBoost'], X_test, y_test, 'XGBoost')\n",
    "\n",
    "# ROC Curve and AUC Calculation for XGBoost - Training Data\n",
    "y_train_bin_xgb = label_binarize(y_train_smote, classes=[0, 1, 2])  # Adjust classes as needed\n",
    "fpr_train_xgb, tpr_train_xgb, roc_auc_train_xgb = {}, {}, {}\n",
    "for i in range(y_train_bin_xgb.shape[1]):\n",
    "    fpr_train_xgb[i], tpr_train_xgb[i], _ = roc_curve(y_train_bin_xgb[:, i], y_train_proba_xgb[:, i])\n",
    "    roc_auc_train_xgb[i] = auc(fpr_train_xgb[i], tpr_train_xgb[i])\n",
    "\n",
    "# ROC Curve and AUC Calculation for XGBoost - Test Data\n",
    "y_test_bin_xgb = label_binarize(y_test, classes=[0, 1, 2])  # Adjust classes as needed\n",
    "fpr_test_xgb, tpr_test_xgb, roc_auc_test_xgb = {}, {}, {}\n",
    "for i in range(y_test_bin_xgb.shape[1]):\n",
    "    fpr_test_xgb[i], tpr_test_xgb[i], _ = roc_curve(y_test_bin_xgb[:, i], y_test_proba_xgb[:, i])\n",
    "    roc_auc_test_xgb[i] = auc(fpr_test_xgb[i], tpr_test_xgb[i])\n",
    "\n",
    "# Plotting the ROC curve for both training and test data\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['blue', 'red', 'green']  # Adjust colors for different classes as needed\n",
    "\n",
    "# Plot ROC curve for each class - Training data\n",
    "for i in range(y_train_bin_xgb.shape[1]):\n",
    "    plt.plot(fpr_train_xgb[i], tpr_train_xgb[i], color=colors[i], linestyle='--', label=f'Train Class {i} AUC = {roc_auc_train_xgb[i]:.4f}')\n",
    "\n",
    "# Plot ROC curve for each class - Test data\n",
    "for i in range(y_test_bin_xgb.shape[1]):\n",
    "    plt.plot(fpr_test_xgb[i], tpr_test_xgb[i], color=colors[i], label=f'Test Class {i} AUC = {roc_auc_test_xgb[i]:.4f}')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Random classifier line\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for XGBoost - Train vs Test')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bf02b3-b3c1-47e9-aedd-b255c2871f79",
   "metadata": {},
   "source": [
    "# Final Comments:\n",
    "\n",
    "Top Performers:\n",
    "1. Random Forest (RF) and XGBoost did the best, showing strong results in accuracy and AUC.\n",
    "2. RF reached 86.68% accuracy with hyperparameter tuning and 10-Fold CV.\n",
    "3. XGBoost was close, with 86.17% accuracy and great class separation (AUC = 0.9448).\n",
    "\n",
    "Ensemble Models (Voting & Stacking):\n",
    "1. Voting Classifier and Stacking combined multiple models but didn’t really improve performance much.\n",
    "2. They had similar test accuracy (80.1%) and AUC scores compared to RF and XGBoost.\n",
    "3. Overfitting was still a problem with these ensembles (training vs. test performance gap).\n",
    "\n",
    "Why the Ensembles Didn’t Help Much:\n",
    "1. RF and XGBoost are already strong models, so combining them with similar models didn’t add much value.\n",
    "2. Ensembles might not fix overfitting problems; they just aggregate existing models without diversity.\n",
    "\n",
    "Next Steps for Improvement:\n",
    "1. Revisit Feature Engineering:Create more domain-specific features or feature interactions (e.g., polynomial features) and implementing feature selection techniques to refine your model inputs. Features like HeartRate that dont give much information could be dropped.\n",
    "2. Examine Data Quality:The duplicates could be removed and the remaiming outliers could be dealt with to reduce their impact.\n",
    "3. Model Interpretation:Use SHAP or LIME to interpret model decisions, potentially uncovering useful feature interactions.\n",
    "4. Boosting with More Models:Consider trying LightGBM or CatBoost alongside XGBoost and RF for better performance.\n",
    "5. Ensemble Refinement:Experiment with a broader mix of models (e.g., Gradient Boosting, LightGBM, Neural Networks) in your ensemble approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47b4033-b4d0-47a0-868d-feefcfc59400",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
